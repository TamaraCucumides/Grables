{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -U \"autogluon.tabular[all]\" --quiet # For training tabular model"
      ],
      "metadata": {
        "id": "9fR0gNITJN-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNziUzq9nTdU"
      },
      "outputs": [],
      "source": [
        "# Install required packages.\n",
        "!pip install torch==2.4.0\n",
        "!pip install torch-geometric torch-sparse torch-scatter torch-cluster torch-spline-conv pyg-lib -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install pytorch_frame --quiet\n",
        "!pip install relbench --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-07-26T00:05:04.397024Z",
          "iopub.status.busy": "2024-07-26T00:05:04.396612Z",
          "iopub.status.idle": "2024-07-26T00:05:05.049064Z",
          "shell.execute_reply": "2024-07-26T00:05:05.048407Z",
          "shell.execute_reply.started": "2024-07-26T00:05:04.397003Z"
        },
        "id": "TYlL1R5x-Vu0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import relbench\n",
        "\n",
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch_geometric\n",
        "import torch_frame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from relbench.datasets import get_dataset\n",
        "\n",
        "dataset = get_dataset(name=\"rel-trial\", download=True)"
      ],
      "metadata": {
        "id": "lpj3A-cf8WKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DWB-Kf6nl2y"
      },
      "outputs": [],
      "source": [
        "from torch.nn import BCEWithLogitsLoss, L1Loss\n",
        "from relbench.datasets import get_dataset\n",
        "\n",
        "from relbench.tasks import get_task\n",
        "\n",
        "db = dataset.get_db()\n",
        "\n",
        "table = db.table_dict[\"studies\"]\n",
        "task = get_task(\"rel-trial\", \"study-outcome\", download=True)\n",
        "\n",
        "train_task = task.get_table(\"train\").df\n",
        "val_task = task.get_table(\"val\").df\n",
        "test_task = task.get_table(\"test\").df\n",
        "\n",
        "## learning table\n",
        "\n",
        "train_df = train_task.merge(table.df, how=\"left\")\n",
        "val_df = val_task.merge(table.df, how=\"left\")\n",
        "test_df = test_task.merge(table.df, how=\"left\")\n",
        "\n",
        "## learning table\n",
        "\n",
        "df_train = train_task.merge(table.df, how=\"left\")\n",
        "df_val = val_task.merge(table.df, how=\"left\")\n",
        "df_test = test_task.merge(table.df, how=\"left\")\n",
        "\n",
        "out_channels = 1\n",
        "loss_fn = L1Loss()\n",
        "tune_metric = \"roc_auc\"\n",
        "higher_is_better = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNzfdwsrkPIo"
      },
      "outputs": [],
      "source": [
        "# Some book keeping\n",
        "from torch_geometric.seed import seed_everything\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "root_dir = \"./data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y79g5H0kVjX"
      },
      "source": [
        "# Build the graph (dont consider text, will be added later in the tab method)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiV3TGI-kRuy"
      },
      "outputs": [],
      "source": [
        "from relbench.modeling.utils import get_stype_proposal\n",
        "\n",
        "db = dataset.get_db()\n",
        "col_to_stype_dict = get_stype_proposal(db)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Identify text columns\n",
        "\n",
        "stype = torch_frame.stype\n",
        "\n",
        "text_columns = [\n",
        "    (table_name, column_name)\n",
        "    for table_name, column_map in col_to_stype_dict.items()\n",
        "    for column_name, column_stype in column_map.items()\n",
        "    if column_stype == stype.text_embedded\n",
        "]"
      ],
      "metadata": {
        "id": "jGCjPT0eAfZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop columns\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "columns_to_drop_by_table = defaultdict(list)\n",
        "\n",
        "for table_name, column_name in text_columns:\n",
        "    columns_to_drop_by_table[table_name].append(column_name)\n",
        "\n",
        "for table_name, columns in columns_to_drop_by_table.items():\n",
        "    df = db.table_dict[table_name].df\n",
        "    existing_columns = [c for c in columns if c in df.columns]\n",
        "\n",
        "    if existing_columns:\n",
        "        db.table_dict[table_name].df = df.drop(columns=existing_columns)"
      ],
      "metadata": {
        "id": "sMNcq2s1C1TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for table_name, column_name in text_columns:\n",
        "    col_to_stype_dict[table_name].pop(column_name, None)"
      ],
      "metadata": {
        "id": "DAuEXWhTDZmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create REG"
      ],
      "metadata": {
        "id": "gN6nPIPUTk0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from relbench.modeling.graph import make_pkey_fkey_graph\n",
        "\n",
        "data, col_stats_dict = make_pkey_fkey_graph(\n",
        "    db,\n",
        "    col_to_stype_dict=col_to_stype_dict,  # speficied column types\n",
        "    #text_embedder_cfg=text_embedder_cfg,  # our chosen text encoder\n",
        "    cache_dir=os.path.join(\n",
        "        root_dir, f\"rel-f1_materialized_cache\"\n",
        "    ),  # store materialized graph for convenience\n",
        ")"
      ],
      "metadata": {
        "id": "PJ1t3X08LdbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_table = task.get_table(\"train\")\n",
        "val_table = task.get_table(\"val\")\n",
        "test_table = task.get_table(\"test\")"
      ],
      "metadata": {
        "id": "1wpCrAGz8yOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUHVG-g6lM-b"
      },
      "outputs": [],
      "source": [
        "from relbench.modeling.graph import get_node_train_table_input, make_pkey_fkey_graph\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "\n",
        "loader_dict = {}\n",
        "\n",
        "for split, table in [\n",
        "    (\"train\", train_table),\n",
        "    (\"val\", val_table),\n",
        "    (\"test\", test_table),\n",
        "]:\n",
        "    table_input = get_node_train_table_input(\n",
        "        table=table,\n",
        "        task=task,\n",
        "    )\n",
        "    entity_table = table_input.nodes[0]\n",
        "    loader_dict[split] = NeighborLoader(\n",
        "        data,\n",
        "        num_neighbors=[\n",
        "            64 for i in range(2)\n",
        "        ],  # we sample subgraphs of depth 2, 128 neighbors per node.\n",
        "        time_attr=\"time\",\n",
        "        input_nodes=table_input.nodes,\n",
        "        input_time=table_input.time,\n",
        "        transform=table_input.transform,\n",
        "        batch_size=512,\n",
        "        temporal_strategy=\"uniform\",\n",
        "        shuffle=split == \"train\",\n",
        "        num_workers=0,\n",
        "        persistent_workers=False,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQc8BWsGludR"
      },
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3m3jEqClQnw"
      },
      "outputs": [],
      "source": [
        "from torch.nn import BCEWithLogitsLoss\n",
        "import copy\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.nn import Embedding, ModuleDict\n",
        "from torch_frame.data.stats import StatType\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import MLP\n",
        "from torch_geometric.typing import NodeType\n",
        "\n",
        "from relbench.modeling.nn import HeteroEncoder, HeteroGraphSAGE, HeteroTemporalEncoder\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: HeteroData,\n",
        "        col_stats_dict: Dict[str, Dict[str, Dict[StatType, Any]]],\n",
        "        num_layers: int,\n",
        "        channels: int,\n",
        "        out_channels: int,\n",
        "        aggr: str,\n",
        "        norm: str,\n",
        "        # List of node types to add shallow embeddings to input\n",
        "        shallow_list: List[NodeType] = [],\n",
        "        # ID awareness\n",
        "        id_awareness: bool = False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = HeteroEncoder(\n",
        "            channels=channels,\n",
        "            node_to_col_names_dict={\n",
        "                node_type: data[node_type].tf.col_names_dict\n",
        "                for node_type in data.node_types\n",
        "            },\n",
        "            node_to_col_stats=col_stats_dict,\n",
        "        )\n",
        "        self.temporal_encoder = HeteroTemporalEncoder(\n",
        "            node_types=[\n",
        "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
        "            ],\n",
        "            channels=channels,\n",
        "        )\n",
        "        self.gnn = HeteroGraphSAGE(\n",
        "            node_types=data.node_types,\n",
        "            edge_types=data.edge_types,\n",
        "            channels=channels,\n",
        "            aggr=aggr,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "        self.head = MLP(\n",
        "            channels,\n",
        "            out_channels=out_channels,\n",
        "            norm=norm,\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.embedding_dict = ModuleDict(\n",
        "            {\n",
        "                node: Embedding(data.num_nodes_dict[node], channels)\n",
        "                for node in shallow_list\n",
        "            }\n",
        "        )\n",
        "\n",
        "        self.id_awareness_emb = None\n",
        "        if id_awareness:\n",
        "            self.id_awareness_emb = torch.nn.Embedding(1, channels)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.encoder.reset_parameters()\n",
        "        self.temporal_encoder.reset_parameters()\n",
        "        self.gnn.reset_parameters()\n",
        "        self.head.reset_parameters()\n",
        "        for embedding in self.embedding_dict.values():\n",
        "            torch.nn.init.normal_(embedding.weight, std=0.1)\n",
        "        if self.id_awareness_emb is not None:\n",
        "            self.id_awareness_emb.reset_parameters()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "            batch.num_sampled_nodes_dict,\n",
        "            batch.num_sampled_edges_dict,\n",
        "        )\n",
        "\n",
        "        return self.head(x_dict[entity_table][: seed_time.size(0)])\n",
        "\n",
        "\n",
        "    def encode_seed_nodes(self, batch: HeteroData, entity_table: NodeType) -> Tensor:\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(seed_time, batch.time_dict, batch.batch_dict)\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "            batch.num_sampled_nodes_dict,\n",
        "            batch.num_sampled_edges_dict,\n",
        "        )\n",
        "\n",
        "        return x_dict[entity_table][: seed_time.size(0)]\n",
        "\n",
        "    def forward_dst_readout(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "        dst_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        if self.id_awareness_emb is None:\n",
        "            raise RuntimeError(\n",
        "                \"id_awareness must be set True to use forward_dst_readout\"\n",
        "            )\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "        # Add ID-awareness to the root node\n",
        "        x_dict[entity_table][: seed_time.size(0)] += self.id_awareness_emb.weight\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "        )\n",
        "\n",
        "        return self.head(x_dict[dst_table])\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    data=data,\n",
        "    col_stats_dict=col_stats_dict,\n",
        "    num_layers=2,\n",
        "    channels=128,\n",
        "    out_channels=1,\n",
        "    aggr=\"mean\",\n",
        "    norm=\"batch_norm\",\n",
        ").to(device) #hyperparameters from Relbench Paper\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAHRIr15lVs6"
      },
      "outputs": [],
      "source": [
        "def train() -> float:\n",
        "    model.train()\n",
        "\n",
        "    loss_accum = count_accum = 0\n",
        "    for batch in tqdm(loader_dict[\"train\"]):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "\n",
        "        loss = loss_fn(pred.float(), batch[entity_table].y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_accum += loss.detach().item() * pred.size(0)\n",
        "        count_accum += pred.size(0)\n",
        "\n",
        "    return loss_accum / count_accum\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader: NeighborLoader) -> np.ndarray:\n",
        "    model.eval()\n",
        "\n",
        "    pred_list = []\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "        pred_list.append(pred.detach().cpu())\n",
        "    return torch.cat(pred_list, dim=0).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yF3W68Eqlew_"
      },
      "outputs": [],
      "source": [
        "state_dict = None\n",
        "best_val_metric = -math.inf if higher_is_better else math.inf\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = train()\n",
        "    val_pred = test(loader_dict[\"val\"])\n",
        "    val_metrics = task.evaluate(val_pred, val_table)\n",
        "    print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "\n",
        "    if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
        "        not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
        "    ):\n",
        "        best_val_metric = val_metrics[tune_metric]\n",
        "        state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "val_pred = test(loader_dict[\"val\"])\n",
        "val_metrics = task.evaluate(val_pred, val_table)\n",
        "print(f\"Best Val metrics: {val_metrics}\")\n",
        "\n",
        "test_pred = test(loader_dict[\"test\"])\n",
        "test_metrics = task.evaluate(test_pred)\n",
        "print(f\"Best test metrics: {test_metrics}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58i-5Z508liB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_seed_embeddings(loader: NeighborLoader):\n",
        "    model.eval()\n",
        "    entity_table = task.entity_table\n",
        "\n",
        "    all_ids = []\n",
        "    all_emb = []\n",
        "\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        seed_n = batch[entity_table].seed_time.size(0)\n",
        "\n",
        "        # IDs and embeddings are on GPU here:\n",
        "        seed_ids = batch[entity_table].n_id[:seed_n]\n",
        "        seed_emb = model.encode_seed_nodes(batch, entity_table)\n",
        "\n",
        "        # Move to CPU only for storage/return:\n",
        "        all_ids.append(seed_ids.detach().cpu())\n",
        "        all_emb.append(seed_emb.detach().cpu())\n",
        "\n",
        "    ids = torch.cat(all_ids, dim=0).numpy()\n",
        "    emb = torch.cat(all_emb, dim=0).numpy()\n",
        "    return ids, emb\n",
        "\n",
        "# Usage:\n",
        "train_ids, train_emb = extract_seed_embeddings(loader_dict[\"train\"])\n",
        "val_ids, val_emb = extract_seed_embeddings(loader_dict[\"val\"])\n",
        "test_ids, test_emb = extract_seed_embeddings(loader_dict[\"test\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the original table"
      ],
      "metadata": {
        "id": "4W7QobucIf7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entity_table = task.entity_table\n",
        "entity_df = db.table_dict[entity_table].df.reset_index(drop=True).copy()\n",
        "\n",
        "# node_id is the row position used by PyG for that node type\n",
        "entity_df[\"node_id\"] = np.arange(len(entity_df), dtype=np.int64)\n",
        "\n",
        "# Keep only what we need:\n",
        "node_to_nct = entity_df[[\"node_id\", \"nct_id\"]]\n"
      ],
      "metadata": {
        "id": "nWx3QsNcSl2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_emb_df(ids: np.ndarray, emb: np.ndarray, split: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    ids: shape (N,)\n",
        "    emb: shape (N, D)\n",
        "    \"\"\"\n",
        "    ids = ids.astype(np.int64)\n",
        "\n",
        "    emb_df = pd.DataFrame(\n",
        "        emb,\n",
        "        columns=[f\"gnn_{i}\" for i in range(emb.shape[1])]\n",
        "    )\n",
        "\n",
        "    df = pd.concat(\n",
        "        [\n",
        "            pd.DataFrame({\"node_id\": ids}),\n",
        "            emb_df,\n",
        "            pd.Series(split, index=ids.index if hasattr(ids, \"index\") else range(len(ids)), name=\"split\"),\n",
        "        ],\n",
        "        axis=1,\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "train_emb_df = make_emb_df(train_ids, train_emb, \"train\").merge(node_to_nct, on=\"node_id\", how=\"left\")\n",
        "val_emb_df   = make_emb_df(val_ids,   val_emb,   \"val\").merge(node_to_nct, on=\"node_id\", how=\"left\")\n",
        "test_emb_df  = make_emb_df(test_ids,  test_emb,  \"test\").merge(node_to_nct, on=\"node_id\", how=\"left\")\n",
        "\n",
        "# Sanity check: ensure mapping worked\n",
        "assert train_emb_df[\"nct_id\"].isna().sum() == 0, \"Some train node_ids did not map to nct_id\"\n",
        "assert val_emb_df[\"nct_id\"].isna().sum() == 0, \"Some val node_ids did not map to nct_id\"\n",
        "assert test_emb_df[\"nct_id\"].isna().sum() == 0, \"Some test node_ids did not map to nct_id\"\n"
      ],
      "metadata": {
        "id": "2xZjcRCCTRVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create augmented dataframes (merge train_df with train_emb df on nct_id, same with val and test)\n",
        "\n",
        "df_train_aug = train_df.merge(train_emb_df, on=\"nct_id\", how=\"left\")\n",
        "df_val_aug   = val_df.merge(val_emb_df, on=\"nct_id\", how=\"left\")\n",
        "df_test_aug  = test_df.merge(test_emb_df, on=\"nct_id\", how=\"left\")"
      ],
      "metadata": {
        "id": "1tMHdx0C51Pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "\n",
        "\n",
        "path = \"/models/\"\n",
        "\n",
        "predictor = TabularPredictor(\n",
        "    label=\"outcome\",\n",
        "    path=path,\n",
        "    eval_metric=\"roc_auc\",  # or \"roc_auc\", \"rmse\", etc.\n",
        ").fit(\n",
        "    train_data=df_train_aug,\n",
        "    tuning_data=df_val_aug,\n",
        "    time_limit=3600,\n",
        "    presets=\"medium_quality\",   # strong; uses bagging/stacking\n",
        "    included_model_types=[\n",
        "        \"GBM\",      # LightGBM\n",
        "        \"CAT\",      # CatBoost\n",
        "        \"XGB\",      # XGBoost\n",
        "        \"RF\",       # optional\n",
        "        \"XT\",       # optional\n",
        "        \"REALMLP\",  # MLP (if available)\n",
        "        # optionally: \"NN_TORCH\" (depending on your AG version/install)\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "TLtbDBtDT7N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.leaderboard(df_val_aug, silent=True).head(20)"
      ],
      "metadata": {
        "id": "x4U1oNVq6rUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proba  = predictor.predict_proba(df_test_aug)\n",
        "preds_proba = proba[1]\n",
        "\n",
        "results = task.evaluate(preds_proba)\n",
        "\n",
        "print(task.evaluate(preds_proba))"
      ],
      "metadata": {
        "id": "y4kHDtYt6vTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_PATH = '/run/'\n",
        "\n",
        "df_GNN_DB = pd.DataFrame([results])\n",
        "df_GNN_DB[\"model\"] = \"Tab+GNN(DB)\"\n",
        "df_GNN_DB[\"task\"] = task\n",
        "\n",
        "df_GNN_DB.to_csv(OUTPUT_PATH+f\"Tab+GNN_DB_Trial_{task}.csv\")"
      ],
      "metadata": {
        "id": "axoYeqh79j4i"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}