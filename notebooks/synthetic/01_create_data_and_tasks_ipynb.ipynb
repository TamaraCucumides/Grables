{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "TCf4Sq0UvRCc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Synthetic transactions data generator\n",
        "\n",
        "def make_synthetic_transactions(\n",
        "    n_rows=10_000,\n",
        "    n_unique_cards=8_000,\n",
        "    n_unique_merchants=7_500,\n",
        "    online_share=0.22,\n",
        "    seed=42,\n",
        "):\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    # Sanity checks\n",
        "    if n_rows > 10_000:\n",
        "        raise ValueError(\"n_rows must be <= 10,000\")\n",
        "    if n_unique_cards > n_rows:\n",
        "        raise ValueError(\"n_unique_cards cannot exceed n_rows (or you cannot realize all unique cards).\")\n",
        "\n",
        "    # Candidate city pool + Online\n",
        "    cities = [\n",
        "        \"Brussels\", \"Antwerp\", \"Ghent\", \"Charleroi\", \"Li√®ge\", \"Bruges\", \"Leuven\", \"Namur\",\n",
        "        \"Paris\", \"London\", \"Amsterdam\", \"Berlin\", \"Madrid\", \"Rome\", \"Vienna\", \"Zurich\",\n",
        "        \"Barcelona\", \"Rotterdam\", \"Lille\", \"Toulouse\"\n",
        "    ]\n",
        "\n",
        "    # Build merchant dimension: each merchant is either Online or tied to a city\n",
        "    merchant_ids = np.arange(1, n_unique_merchants + 1, dtype=np.int64)\n",
        "\n",
        "    merchant_is_online = rng.random(n_unique_merchants) < online_share\n",
        "    merchant_city = np.where(\n",
        "        merchant_is_online,\n",
        "        \"ONLINE\",\n",
        "        rng.choice(cities, size=n_unique_merchants, replace=True)\n",
        "    )\n",
        "\n",
        "    merchant_dim = pd.DataFrame({\n",
        "        \"merchant_id\": merchant_ids,\n",
        "        \"merchant_city\": merchant_city\n",
        "    })\n",
        "\n",
        "    # Build card_id pool (exact count)\n",
        "    # Using strings makes IDs look realistic and avoids accidental numeric formatting issues in CSVs.\n",
        "    card_pool = np.array([f\"C{idx:06d}\" for idx in range(1, n_unique_cards + 1)])\n",
        "\n",
        "    # Ensure ALL cards appear at least once:\n",
        "    # 1) place each card once for the first n_unique_cards rows\n",
        "    # 2) sample remaining rows with a mild skew (some cards used more than others)\n",
        "    base_cards = card_pool.copy()\n",
        "\n",
        "    remaining = n_rows - n_unique_cards\n",
        "    if remaining > 0:\n",
        "        # Create a skewed distribution over cards (Zipf-like but bounded)\n",
        "        weights = 1 / (np.arange(1, n_unique_cards + 1) ** 0.8)\n",
        "        weights = weights / weights.sum()\n",
        "        extra_cards = rng.choice(card_pool, size=remaining, replace=True, p=weights)\n",
        "        card_ids = np.concatenate([base_cards, extra_cards])\n",
        "    else:\n",
        "        card_ids = base_cards\n",
        "\n",
        "    # Sample merchants for transactions; you can skew to simulate \"big merchants\"\n",
        "    merchant_weights = 1 / (np.arange(1, n_unique_merchants + 1) ** 0.7)\n",
        "    merchant_weights = merchant_weights / merchant_weights.sum()\n",
        "    tx_merchant_ids = rng.choice(merchant_ids, size=n_rows, replace=True, p=merchant_weights)\n",
        "\n",
        "    # Assemble transactions and attach merchant_city\n",
        "    df = pd.DataFrame({\n",
        "        \"id\": np.arange(1, n_rows + 1, dtype=np.int64),\n",
        "        \"card_id\": card_ids,\n",
        "        \"merchant_id\": tx_merchant_ids\n",
        "    }).merge(merchant_dim, on=\"merchant_id\", how=\"left\")\n",
        "\n",
        "    # Shuffle rows so the first 6,000 rows aren't \"one-per-card\" in order\n",
        "    df = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
        "\n",
        "    # Recreate id after shuffle to keep it clean and sequential\n",
        "    df[\"id\"] = np.arange(1, n_rows + 1, dtype=np.int64)\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "uvWmMU57Mmkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Instantiate logical tasks\n",
        "\n",
        "\n",
        "from enum import unique\n",
        "def create_task_unique(df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Adds a new column indicating whether values in `column` are unique.\n",
        "    The new column is named `unique_<column>` and contains:\n",
        "      - 1 if the value appears exactly once in the column\n",
        "      - 0 otherwise\n",
        "    \"\"\"\n",
        "    unique_col_name = f\"unique_{column}\"\n",
        "    value_counts = df[column].value_counts()\n",
        "    df[unique_col_name] = df[column].map(value_counts).eq(1).astype(int)\n",
        "    return df\n",
        "\n",
        "def create_task_count(df: pd.DataFrame, column: str, k: int, greater_than: bool = True) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Adds a new column indicating whether values in `column` meet a count condition.\n",
        "\n",
        "    The new column is named:\n",
        "      - `count_gt_<k>_<column>` if greater_than is True\n",
        "      - `count_eq_<k>_<column>` if greater_than is False\n",
        "\n",
        "    Values:\n",
        "      - 1 if the value appears more than k times (greater_than=True),\n",
        "        otherwise exactly k times\n",
        "      - 0 otherwise\n",
        "    \"\"\"\n",
        "    suffix = \"gt\" if greater_than else \"eq\"\n",
        "    new_col_name = f\"count_{suffix}_{k}_{column}\"\n",
        "\n",
        "    value_counts = df[column].value_counts()\n",
        "\n",
        "    if greater_than:\n",
        "        mask = df[column].map(value_counts).gt(k)\n",
        "    else:\n",
        "        mask = df[column].map(value_counts).eq(k)\n",
        "\n",
        "    df[new_col_name] = mask.astype(int)\n",
        "    return df\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def create_task_double(df: pd.DataFrame, col_1: str, col_2: str, anchor) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Adds a new column indicating whether there exists ANOTHER row\n",
        "    with the same value in `col_1` and with `col_2 == anchor`.\n",
        "\n",
        "    The new column is named `double_<col_1>_<col_2>_<anchor>`.\n",
        "\n",
        "    Values:\n",
        "      - 1 if there exists another row with the same `col_1`\n",
        "        and with `col_2 == anchor`\n",
        "      - 0 otherwise\n",
        "    \"\"\"\n",
        "    new_col_name = f\"double_{col_1}_{col_2}_{anchor}\"\n",
        "\n",
        "    # Count how many anchor rows exist per col_1\n",
        "    anchor_counts = (\n",
        "        df[col_2].eq(anchor)\n",
        "        .groupby(df[col_1])\n",
        "        .sum()\n",
        "    )\n",
        "\n",
        "    # Map counts back to rows\n",
        "    counts_per_row = df[col_1].map(anchor_counts).fillna(0)\n",
        "\n",
        "    # Exists \"other\" row logic\n",
        "    df[new_col_name] = (\n",
        "        ((df[col_2] != anchor) & (counts_per_row >= 1)) |\n",
        "        ((df[col_2] == anchor) & (counts_per_row >= 2))\n",
        "    ).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_task_diamond(df: pd.DataFrame, col_1: str, col_2: str, strict=False) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Adds a new column indicating whether there exists another row\n",
        "    with the same (`col_1`, `col_2`) combination.\n",
        "\n",
        "    The new column is named `duplicate_<col_1>_<col_2>`.\n",
        "\n",
        "    Values:\n",
        "      - 1 if the (`col_1`, `col_2`) pair appears more than once\n",
        "      - 0 otherwise\n",
        "    \"\"\"\n",
        "\n",
        "    counts = df.groupby([col_1, col_2])[col_1].transform(\"size\")\n",
        "    if strict:\n",
        "      new_col_name = f\"duplicate_{col_1}_{col_2}_strict\"\n",
        "      df[new_col_name] = (counts == 2).astype(int)\n",
        "    else:\n",
        "      new_col_name = f\"duplicate_{col_1}_{col_2}\"\n",
        "      df[new_col_name] = (counts > 1).astype(int)\n",
        "\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "Sa1D4qMOv6YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_PATH = 'data/processed/'\n",
        "\n",
        "df_train = make_synthetic_transactions(\n",
        "    n_rows=8_000,\n",
        "    n_unique_cards=2_500,\n",
        "    n_unique_merchants=3_500,\n",
        "    online_share=0.15,\n",
        ")\n",
        "\n",
        "df_val = make_synthetic_transactions(\n",
        "    n_rows=1_000,\n",
        "    n_unique_cards=350,\n",
        "    n_unique_merchants=300,\n",
        "    online_share=0.12,\n",
        ")\n",
        "\n",
        "df_test = make_synthetic_transactions(\n",
        "    n_rows=1_000,\n",
        "    n_unique_cards=350,\n",
        "    n_unique_merchants=300,\n",
        "    online_share=0.12,\n",
        ")\n",
        "\n",
        "\n",
        "for df in [df_train, df_val, df_test]:\n",
        "  df = create_task_unique(df, 'merchant_id')\n",
        "  df = create_task_count(df, 'card_id', 12)\n",
        "  df = create_task_count(df, 'card_id', 3, greater_than=False)\n",
        "  df = create_task_double(df, 'card_id', 'merchant_city', \"ONLINE\")\n",
        "  df = create_task_diamond(df, 'card_id', 'merchant_city')\n",
        "  df = create_task_diamond(df, 'card_id', 'merchant_city', strict=False)\n"
      ],
      "metadata": {
        "id": "9UJxmA9BViiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.to_csv(OUTPUT_PATH+'synth-df_train.csv')\n",
        "df_val.to_csv(OUTPUT_PATH+'synth-df_val.csv')\n",
        "df_test.to_csv(OUTPUT_PATH+'synth-df_test.csv')"
      ],
      "metadata": {
        "id": "7J6JnY8XV0xj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}